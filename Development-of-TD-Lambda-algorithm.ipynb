{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coding of TD($\\lambda$) learner algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.7.4'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from platform import python_version\n",
    "python_version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Based on Chapter 12: Eligibility Traces from Sutton & Barto\n",
    "\n",
    "### TD($\\lambda$)\n",
    "\n",
    "<IMG SRC=\"images/tdlambda.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Walk Environment\n",
    "\n",
    "Use the same random walk environment used in Chapter 7 (Example 7.1)\n",
    "\n",
    "This has been implemented in a separate module `randomwalk.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from randomwalk import RandomWalkGame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "game = RandomWalkGame(size=19, terminal_rewards={'T1': -1.0, 'T2': 1.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T1 _ _ _ _ _ _ _ _ _ J _ _ _ _ _ _ _ _ _ T2\n"
     ]
    }
   ],
   "source": [
    "# Initial state\n",
    "game.show_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T1 _ _ _ _ _ _ _ _ _ _ K _ _ _ _ _ _ _ _ T2\n"
     ]
    }
   ],
   "source": [
    "# Moves are 'l' or 'r' (left or right)\n",
    "game.make_move((1, 'r'))\n",
    "game.show_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0.0}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# zero rewards...\n",
    "game.get_rewards()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T1 _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ T2\n"
     ]
    }
   ],
   "source": [
    "# until terminal state reached\n",
    "while not game.state in game.terminal_states:\n",
    "    game.make_move((1, 'r'))\n",
    "game.show_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 1.0}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game.get_terminal_rewards()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For verification purposes, let's try to replicate the results below which should match Figure 12.8 from the book which looks like this:\n",
    "\n",
    "<IMG SRC=\"images/fig_12_8.png\">    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recap: this is the n-step TD update method from chapter 7\n",
    "\n",
    "## N-Step TD Update - for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discounted_sequence_generator(sequence, gamma):\n",
    "    \"\"\"Returns a generator that yields each item of sequence\n",
    "    discounted by gamma at each time-step.\n",
    "    \n",
    "    Example:\n",
    "    >>> list(discounted_sequence_generator([10.0]*5, 0.75))\n",
    "    [10.0, 7.5, 5.625, 4.21875, 3.1640625]\n",
    "    \"\"\"\n",
    "\n",
    "    x = 1.0\n",
    "    for item in sequence:\n",
    "        yield x * item\n",
    "        x = x * gamma\n",
    "\n",
    "\n",
    "def td_n_step_update(n, value_function, prev_states, prev_rewards, tau, gamma,\n",
    "                     learning_rate, t_max=np.inf, show=False):\n",
    "    \"\"\"Updates the value in value_function for the state\n",
    "    that occurred in past timestep tau using the n-step TD\n",
    "    algorithm.\n",
    "    \n",
    "    Note:\n",
    "    tau = t - n + 1\n",
    "\n",
    "    Where:\n",
    "        t is the current timestep\n",
    "        n is the number of steps to look forward  \n",
    "\n",
    "    If tau < 0 no update is possible so none is made.\n",
    "\n",
    "    Args:\n",
    "        value_function (dict): Dictionary of state values.\n",
    "        prev_states (list): List of previous states.\n",
    "        prev_rewards (list): List of previous rewards.\n",
    "        tau (int): The timestep of the state that will have\n",
    "            its value updated.\n",
    "        gamma (float): Discount rate.\n",
    "        learning_rate (float): Learning rate parameter.\n",
    "        t_max (int or np.inf): The maximum timestep to include.  \n",
    "            Set to np.inf or a high number if you want to\n",
    "            include all timesteps from tau to tau + n.  Set\n",
    "            to t if the game has eneded.\n",
    "        show (bool): Print messages if True.\n",
    "    \"\"\"\n",
    "\n",
    "    assert len(prev_states) == len(prev_rewards)\n",
    "\n",
    "    if tau >= 0:\n",
    "\n",
    "        assert tau < len(prev_states), \"Not enough past states.\"\n",
    "\n",
    "        discounted_rewards = discounted_sequence_generator(\n",
    "            prev_rewards[tau+1:min(tau + n, t_max) + 1], \n",
    "            gamma\n",
    "        )\n",
    "        g = sum(list(discounted_rewards))\n",
    "\n",
    "        if tau + n < t_max:\n",
    "            g += gamma**n * value_function[prev_states[tau + n]]\n",
    "\n",
    "        # Update value of state at timestep tau\n",
    "        state_key = prev_states[tau]\n",
    "        state_value = value_function[state_key]\n",
    "\n",
    "        if show:\n",
    "            print(f\"prev_states[{tau}]: {state_value}\")\n",
    "\n",
    "        value_function[state_key] = state_value + \\\n",
    "            learning_rate * (g - state_value)\n",
    "\n",
    "        if show:\n",
    "            print(f\"value_function[{state_key.__repr__()}]: {value_function[state_key]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the equivalent TD($\\lambda$) update calculation\n",
    "\n",
    "## TD($\\lambda$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def td_lambda_weight_update(weights, value_current_state, value_prev_state, reward, \n",
    "                            dv_dw, z, lam, gamma, learning_rate):\n",
    "    \"\"\"Updates the weights of a value function for the \n",
    "    previous state using the TD-Lambda algorithm.\n",
    "    \n",
    "    Args:\n",
    "        weights (array): Array of weights (value function \n",
    "            parameters).\n",
    "        value_current_state (float): Value estimate for current state.\n",
    "        value_prev_state (float): Value estimate for previous state.\n",
    "        reward (float): Reward at current state.\n",
    "        dv_dw (array): Partial derivatives of value function\n",
    "            w.r.t. the weights at current state.\n",
    "        z (array): Eligibility trace vector.\n",
    "        lam (float): Lambda parameter.\n",
    "        gamma (float): Discount factor.\n",
    "        learning_rate (float): Learning rate parameter.\n",
    "    \"\"\"\n",
    "\n",
    "    assert dv_dw.shape == z.shape\n",
    "    z = gamma * lam * z + dv_dw\n",
    "    td_error = reward + gamma * value_current_state - value_prev_state\n",
    "    \n",
    "    return weights + learning_rate * td_error * z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare to this code from here:\n",
    "# https://amreis.github.io/ml/reinf-learn/2017/11/02/reinforcement-learning-eligibility-traces.html\n",
    "#\n",
    "# td_error = reward + gamma * state_values[new_state] - state_values[state]\n",
    "# state_values = state_values + alpha * td_error * eligibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run The Parameter Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Random-Walk Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game = RandomWalkGame(size=19, terminal_rewards={'T1': -1.0, 'T2': 1.0})\n",
    "n_states = len(game.states) - len(game.terminal_states)\n",
    "n_states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMS Error Calculation and True Values\n",
    "\n",
    "This function calculates the true state values (for a random policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.9 -0.8 -0.7 -0.6 -0.5 -0.4 -0.3 -0.2 -0.1  0.   0.1  0.2  0.3  0.4\n",
      "  0.5  0.6  0.7  0.8  0.9]\n"
     ]
    }
   ],
   "source": [
    "def calculate_true_values(game):\n",
    "    \"\"\"Returns a list of the true values of states in a\n",
    "    RandomWalk game.\n",
    "    \"\"\"\n",
    "\n",
    "    xp = [0, game.size+1]\n",
    "    fp = [-1.0, 1.0]\n",
    "\n",
    "    true_values = np.interp(np.arange(game.size + 2), xp, fp)[1:-1]\n",
    "    \n",
    "    return true_values\n",
    "\n",
    "\n",
    "def calculate_rms_error(values, true_values):\n",
    "    \"\"\"Root-mean-squared error of values compared to true values.\n",
    "    \"\"\"\n",
    "\n",
    "    return np.sqrt(np.sum((np.array(values) - \n",
    "                           np.array(true_values))**2)/len(values))\n",
    "\n",
    "# Test true values are correct\n",
    "true_values = calculate_true_values(game)\n",
    "values = np.zeros(n_states)\n",
    "error = calculate_rms_error(values, true_values)\n",
    "assert error == 0.5477225575051662  # Calculated using code from Sutton & Barto\n",
    "\n",
    "print(true_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Value Approximation Functions for use with TD-$\\lambda$\n",
    "\n",
    "To use TD-$\\lambda$ we need a differentiable value function applicable to the problem (i.e. the environment's states and actions).  Here are a couple of general-purpose value function classes that might be useful for the RandomWalk environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplest possible value function - discrete values for each state\n",
    "n_states = len(game.states)\n",
    "state_values = np.zeros(n_states)  # initial guess = 0 value\n",
    "eligibility = np.zeros(n_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a) N-Step TD Updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-d7dd68777fe4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;31m# Test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m \u001b[0mrun_random_walk_with_n_step_td\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-22-d7dd68777fe4>\u001b[0m in \u001b[0;36mrun_random_walk_with_n_step_td\u001b[0;34m(n, learning_rate, gamma, n_episodes, n_reps, initial_value, size, seed)\u001b[0m\n\u001b[1;32m     49\u001b[0m                     \u001b[0mtau\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                     td_n_step_update(n, value_function, past_rewards, past_rewards, tau, \n\u001b[0;32m---> 51\u001b[0;31m                                      gamma, learning_rate)\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-8c3cbd520ac2>\u001b[0m in \u001b[0;36mtd_n_step_update\u001b[0;34m(value_function, prev_states, prev_rewards, tau, gamma, learning_rate, t_max, show)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \"\"\"\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_states\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_rewards\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtau\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def run_random_walk_with_n_step_td(n=10, learning_rate=0.01, gamma=1.0, n_episodes=10, \n",
    "                                   n_reps=1, initial_value=0.0, size=19, seed=1):\n",
    "    \"\"\"Run n_episodes of random walk and calculate the root-\n",
    "    mean-squared errror of the value function after the \n",
    "    last episode.  If n_reps > 1 then the experiment is \n",
    "    repeated n_reps times and the average rms_error returned.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize environment\n",
    "    terminal_rewards = {'T1': -1.0, 'T2': 1.0}\n",
    "    game = RandomWalkGame(size=size, terminal_rewards=terminal_rewards)\n",
    "\n",
    "    # Initialise value function\n",
    "    value_function = {\n",
    "        s: 0.0 if s in game.terminal_states else initial_value\n",
    "        for s in game.states\n",
    "    }\n",
    "\n",
    "    # Random number generator\n",
    "    rng = random.Random(seed)\n",
    "\n",
    "    # Repeat n_reps times\n",
    "    rms_errors = []\n",
    "    for repetition in range(n_reps):\n",
    "        for iteration in range(n_episodes):\n",
    "\n",
    "            past_states = [game.state]\n",
    "            past_rewards = [None]\n",
    "\n",
    "            T = 999999\n",
    "            t = 0\n",
    "            while True:\n",
    "\n",
    "                # Behaviour policy\n",
    "                if t < T:\n",
    "                    move = rng.choice(game.available_moves())\n",
    "                    game.make_move([1, move])\n",
    "                    past_states.append(game.state)\n",
    "                    if not game.game_over:\n",
    "                        reward = game.get_rewards()[1]\n",
    "                    else:\n",
    "                        reward = game.get_terminal_rewards()[1]\n",
    "                    past_rewards.append(reward)\n",
    "                    if game.game_over:\n",
    "                        T = t + 1\n",
    "\n",
    "                if not game.game_over:\n",
    "                    # State to be updated\n",
    "                    tau = t - n + 1\n",
    "                    td_n_step_update(n, value_function, past_rewards, past_rewards, tau, \n",
    "                                     gamma, learning_rate)\n",
    "\n",
    "                else:\n",
    "                    # Complete final state-value updates for timesteps tau\n",
    "                    # to current (terminal) timestep\n",
    "                    T = t + 1\n",
    "                    for tau in range(t - n + 1, T):\n",
    "                        td_n_step_update(n, value_function, past_rewards, past_rewards, tau, \n",
    "                                         gamma, learning_rate, t_max=T)\n",
    "\n",
    "                t += 1\n",
    "                if tau == T - 1:\n",
    "                    break\n",
    "            game.reset()\n",
    "\n",
    "        values = np.array(list(value_function.values())[1:size+1])\n",
    "        rms_error = calculate_rms_error(values, true_values)\n",
    "        rms_errors.append(rms_error)\n",
    "\n",
    "    avg_rms_error = np.array(rms_errors).mean()\n",
    "\n",
    "    # Return param values\n",
    "    params = {\n",
    "        'n': n,\n",
    "        'learning_rate': learning_rate,\n",
    "        'gamma': gamma,\n",
    "        'n_episodes': n_episodes\n",
    "    }\n",
    "\n",
    "    return params, avg_rms_error\n",
    "\n",
    "# Test\n",
    "run_random_walk_with_n_step_td()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiments...\n",
      "n: 1\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'prev_states' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-c4f475fda0c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;32min\u001b[0m \u001b[0malpha_values\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         params, avg_rms_error = run_random_walk_with_n_step_td(n=n_steps, learning_rate=alpha, \n\u001b[0;32m---> 18\u001b[0;31m                                                                n_reps=n_reps, size=n_states)\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mavg_rms_errors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_rms_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-63a31fe47530>\u001b[0m in \u001b[0;36mrun_random_walk_with_n_step_td\u001b[0;34m(n, learning_rate, gamma, n_episodes, n_reps, initial_value, size, seed)\u001b[0m\n\u001b[1;32m     48\u001b[0m                     \u001b[0;31m# State to be updated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                     \u001b[0mtau\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m                     td_n_step_update(value_function, prev_states, prev_rewards, tau, gamma,\n\u001b[0m\u001b[1;32m     51\u001b[0m                                      learning_rate)\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'prev_states' is not defined"
     ]
    }
   ],
   "source": [
    "# Run many repetitions with varying parameter values\n",
    "n_reps = 1\n",
    "\n",
    "# all possible steps\n",
    "n_steps_values = np.power(2, np.arange(0, 10))\n",
    "\n",
    "# all possible alphas\n",
    "alpha_values = np.arange(0, 1.1, 0.1)\n",
    "\n",
    "# Use this dictionary to accumulate the results\n",
    "avg_rms_errors = {}\n",
    "\n",
    "print(f\"Running experiments...\")\n",
    "for n_steps in n_steps_values:\n",
    "    print(f\"n: {n_steps}\")\n",
    "    for alpha in alpha_values:\n",
    "        params, avg_rms_error = run_random_walk_with_n_step_td(n=n_steps, learning_rate=alpha, \n",
    "                                                               n_reps=n_reps, size=n_states)\n",
    "        avg_rms_errors[tuple(params.items())] = avg_rms_error\n",
    "\n",
    "print(f\"{len(avg_rms_errors)} results calculated\")\n",
    "\n",
    "param_values = [dict(x) for x in avg_rms_errors.keys()]\n",
    "rms_error_values = list(avg_rms_errors.values())\n",
    "results_df = pd.concat([pd.DataFrame(param_values), \n",
    "                        pd.Series(rms_error_values, name='RMS error')], \n",
    "                       axis=1)\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110 results calculated\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>gamma</th>\n",
       "      <th>n_episodes</th>\n",
       "      <th>RMS error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.547723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.088929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.133378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.182382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.232419</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n  learning_rate  gamma  n_episodes  RMS error\n",
       "0  1            0.0    1.0          10   0.547723\n",
       "1  1            0.1    1.0          10   0.088929\n",
       "2  1            0.2    1.0          10   0.133378\n",
       "3  1            0.3    1.0          10   0.182382\n",
       "4  1            0.4    1.0          10   0.232419"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"{len(avg_rms_errors)} results calculated\")\n",
    "\n",
    "param_values = [dict(x) for x in avg_rms_errors.keys()]\n",
    "rms_error_values = list(avg_rms_errors.values())\n",
    "results_df = pd.concat([pd.DataFrame(param_values), \n",
    "                        pd.Series(rms_error_values, name='RMS error')], \n",
    "                       axis=1)\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot results\n",
    "results_by_n_value = results_df.groupby('n')\n",
    "fig, ax = plt.subplots()\n",
    "for n, df in results_by_n_value:\n",
    "    rms_errors = df['RMS error']\n",
    "    learning_rates = df['learning_rate']\n",
    "    ax.plot(learning_rates, rms_errors, label=f'n = {n:d}')\n",
    "plt.title('n-step TD value error on random walk (%d states)' % game.size)\n",
    "ax.set_xlabel('Learning rate (alpha)')\n",
    "ax.set_ylabel('RMS Error')\n",
    "ax.set_ylim(0.0, 0.55)\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.savefig(f\"random-walk-n-step-td-{game.size}-{n_reps}.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More interesting function approximation methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can we use or adapt scikit-learn models?\n",
    "\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class FunctionApproximator(ABC):\n",
    "    \"\"\"Abstract function approximation class.\"\"\"\n",
    "\n",
    "    def __init__(self, input_shape, d, output_shape=(1,),\n",
    "                 init_value=0):\n",
    "        \n",
    "        self.input_shape = input_shape\n",
    "        self.output_shape = output_shape\n",
    "        self.d = d\n",
    "        self._weights = np.full(d, init_value)\n",
    "\n",
    "    @property\n",
    "    def weights(self):\n",
    "        return self._weights\n",
    "\n",
    "    @weights.setter\n",
    "    def weights(self, values):\n",
    "        self._weights[:] = values\n",
    "\n",
    "    @abstractmethod\n",
    "    def __call__(self, x):\n",
    "        \"\"\"Returns the function estimate at x. x may\n",
    "        be a single point or sequence of points.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    @abstractmethod\n",
    "    def dw(self, x):\n",
    "        \"\"\"Returns the partial derivatives w.r.t. the weights\n",
    "        (parameters) at x.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "class LinearValueFunctionForDiscreteStates(FunctionApproximator):\n",
    "    \"\"\"Uses the following simple linear functon to approximate\n",
    "    the state-values of an environment:\n",
    "    \n",
    "    v_hat = w_0 + w_1 * x\n",
    "    \n",
    "    where x is a scalar input feature generated from the \n",
    "    environment's state.  For example, this might work well if \n",
    "    the state values are a one-dimensional discretized \n",
    "    representation of a linear one-dimensional state-space\n",
    "    where x represents the position.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, states, terminal_states=None, init_value=0):\n",
    "        \n",
    "        if terminal_states is None:\n",
    "            terminal_states = []\n",
    "            self.states = states\n",
    "        else:\n",
    "            self.states = [s for s in states if s not in terminal_states]\n",
    "        self.terminal_states = terminal_states\n",
    "        self.x = np.full(len(self.states), np.nan)\n",
    "        self.d = len(self.states)\n",
    "        input_shape = (1, )\n",
    "        super().__init__(input_shape, self.d, output_shape=(1,), init_value=init_value)\n",
    "        self.z = np.full_like(self.weights, 0.)\n",
    "\n",
    "    def __call__(self, state):\n",
    "        \"\"\"Returns the value estimate for the given state.\n",
    "        \"\"\"\n",
    "        if state in game.terminal_states:\n",
    "            return 0.\n",
    "        x = self.input_mapping(state)\n",
    "        return np.sum(self.weights * x)\n",
    "    \n",
    "    def input_mapping(self, state):\n",
    "        self.x[:] = 0\n",
    "        self.x[self.states.index(state)] = 1\n",
    "        return self.x\n",
    "    \n",
    "    def dw(self, state):\n",
    "        \"\"\"Returns the partial derivatives of the value \n",
    "        function w.r.t. the weights (parameters) at the\n",
    "        given state.\n",
    "        \"\"\"\n",
    "        if state in game.terminal_states:\n",
    "            # TODO: Is this the correct thing to do?\n",
    "            self.x[:] = 0\n",
    "            x = self.x\n",
    "        else:\n",
    "            x = self.input_mapping(state)\n",
    "        return x\n",
    "\n",
    "    def update_weights(self, current_state, prev_state, reward,\n",
    "                       lam, gamma, learning_rate):\n",
    "        \n",
    "        self.weights[:] = td_lambda_weight_update(\n",
    "            self.weights, \n",
    "            current_state_value=self(current_state), \n",
    "            prev_state_value=self(prev_state), \n",
    "            reward=reward,\n",
    "            dv_dw=self.dw(prev_state),\n",
    "            z=self.z,\n",
    "            lam=lam,\n",
    "            gamma=gamma,\n",
    "            learning_rate=learning_rate\n",
    "        )\n",
    "\n",
    "\n",
    "class ValueFunctionDiscreteStatesLinearApproximator(FunctionApproximator):\n",
    "    \"\"\"Uses the following simple linear functon to approximate\n",
    "    the state-values of an environment:\n",
    "    \n",
    "    v_hat = w_0 + w_1 * x\n",
    "    \n",
    "    where x is a scalar input feature that is generated from\n",
    "    the environment's state assuming all the state values are\n",
    "    a one-dimensional discretized representation of a linear\n",
    "    state-space.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, states):\n",
    "        self.states = states\n",
    "        self.n_states = len(self.states)\n",
    "        self.terminal_states = [s for s in game.terminal_states]\n",
    "        self.weights = np.zeros(2)  # Linear function approximator\n",
    "        self.z = np.full_like(self.weights, 0)  # Eligibility trace vector\n",
    "\n",
    "    def input_mapper(self, state_key):\n",
    "        \"\"\"Converts a discrete state into a (scalar) feature \n",
    "        value assuming all the state values represent a one-\n",
    "        dimensional linear state-space.\n",
    "        \n",
    "        returns:\n",
    "            x (float): (0 <= x <= 1).\n",
    "        \"\"\"\n",
    "        return self.states.index(state_key) / (self.n_states - 1)\n",
    "    \n",
    "    def __getitem__(self, key):\n",
    "        \"\"\"Return values based on state key (or sequence of keys).\n",
    "        \"\"\"\n",
    "        \n",
    "        if isinstance(key, str):\n",
    "            return self.value(key)\n",
    "        if not isinstance(key, np.ndarray):\n",
    "            # Convert a simple index x[y] to an array\n",
    "            key = np.array(key)\n",
    "\n",
    "        # Handle the different dimensional cases\n",
    "        return np.fromiter((self.value(xi) for xi in key), key.dtype)\n",
    "        \n",
    "    def value(self, state_key):\n",
    "        \"\"\"Returns estimate of value of state.\n",
    "        \"\"\"\n",
    "        if state_key in self.terminal_states:\n",
    "            return 0\n",
    "        x = self.map_inputs(state_key)\n",
    "        return self.weights[0] + self.weights[1] * x\n",
    "\n",
    "    def dw(self, state_key):\n",
    "        \"\"\"Partial derivatives of value function w.r.t.\n",
    "        weights at given state.\n",
    "        \"\"\"\n",
    "        if state_key in self.terminal_states:\n",
    "            return np.array([1.0, 0.0])\n",
    "        x = self.map_inputs(state_key)\n",
    "        return np.array([1.0, x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test ValueFunctionDiscreteStates class\n",
    "states = game.states\n",
    "terminal_states = game.terminal_states\n",
    "value_function = ValueFunctionDiscreteStates(states, terminal_states, \n",
    "                                             init_value=0.5)\n",
    "\n",
    "assert len(value_function.states) == 19\n",
    "assert value_function.terminal_states == ['T1', 'T2']\n",
    "assert value_function.d == 19\n",
    "assert value_function.input_shape == (1,)\n",
    "assert value_function.weights.shape == (19,)\n",
    "assert value_function.z.shape == (19,)\n",
    "assert value_function.x.shape == (19,)\n",
    "assert np.all(value_function.weights == 0.5)\n",
    "assert np.all(value_function.z == 0)\n",
    "assert all([value_function(s) == 0.5 for s in value_function.states])\n",
    "assert all([value_function(s) == 0.0 for s in \n",
    "            value_function.terminal_states])\n",
    "assert np.array_equal(\n",
    "    value_function.dw('D'),\n",
    "    np.array([0., 0., 0., 1., 0., 0., 0., 0., 0., \n",
    "              0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
    ")\n",
    "value_function.weights = [0]*19\n",
    "assert np.array_equal(\n",
    "    value_function.weights,\n",
    "    np.array([0., 0., 0., 0., 0., 0., 0., 0., 0., \n",
    "              0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
    ")\n",
    "current_state = 'K'\n",
    "prev_state = 'J'\n",
    "reward = 1\n",
    "lam = 0.5\n",
    "gamma = 1.0\n",
    "learning_rate = 0.1\n",
    "value_function.update_weights(current_state, prev_state, reward,\n",
    "                              lam, gamma, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.array_equal(\n",
    "    value_function.weights,\n",
    "    np.array([0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , \n",
    "              0.1, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ])\n",
    ")\n",
    "prev_state = current_state\n",
    "current_state = 'L'\n",
    "reward = 1\n",
    "lam = 0.5\n",
    "gamma = 1.0\n",
    "learning_rate = 0.1\n",
    "value_function.update_weights(current_state, prev_state, reward,\n",
    "                              lam, gamma, learning_rate)\n",
    "assert np.isclose(\n",
    "    value_function.weights,\n",
    "    np.array([0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.1, \n",
    "              0.1, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ])\n",
    ").all()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "value_function = ValueFunctionDiscreteStatesLinearApproximator(game)\n",
    "\n",
    "# Mapping states to a single input feature\n",
    "index = pd.Index(value_function.states, name='State')\n",
    "pd.DataFrame({\n",
    "    'x': {s: value_function.map_inputs(s) for s in value_function.states},\n",
    "    'Value estimate': value_function[value_function.states]\n",
    "}, index=index)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "value_function.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test 1 - Single Episode / Walk Right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a) N-Step TD Updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General TD parameters\n",
    "gamma = 1.0\n",
    "learning_rate = 0.1\n",
    "initial_value = 0.0\n",
    "\n",
    "# N-step TD parameters\n",
    "n = 10\n",
    "value_function = {state_key: initial_value for state_key in game.states}\n",
    "\n",
    "# Environment setup\n",
    "game = RandomWalkGame(size=19, terminal_rewards={'T1': -1.0, 'T2': 1.0})\n",
    "actions = ['r']*10\n",
    "role = 1\n",
    "\n",
    "prev_states = [game.start_state]\n",
    "prev_rewards = [None]\n",
    "t = 0\n",
    "while not game.game_over:\n",
    "\n",
    "    # Behaviour policy\n",
    "    move = (role, actions[t])\n",
    "    game.make_move(move)\n",
    "\n",
    "    # Get rewards\n",
    "    if not game.game_over:\n",
    "        reward = game.get_rewards()[role]\n",
    "    else:\n",
    "        reward = game.get_terminal_rewards()[role]\n",
    "\n",
    "    print(f\"{prev_states[-1]} -> {game.state}, {reward}\")\n",
    "\n",
    "    state_key = game.generate_state_key(game.state, role)\n",
    "    prev_states.append(state_key)\n",
    "    prev_rewards.append(reward)\n",
    "\n",
    "    if not game.game_over:\n",
    "        # Update the value for state in timestep tau\n",
    "        tau = t - n + 1\n",
    "        td_n_step_update(value_function, prev_states, prev_rewards, \n",
    "                         tau, gamma, learning_rate)\n",
    "\n",
    "    # Update timestep\n",
    "    t += 1\n",
    "\n",
    "assert game.game_over\n",
    "\n",
    "# Complete final state-value updates for timesteps tau\n",
    "# to current (terminal) timestep\n",
    "for tau in range(t - n, t):\n",
    "    td_n_step_update(value_function, prev_states, prev_rewards, \n",
    "                     tau, gamma, learning_rate, t_max=t)\n",
    "\n",
    "# Value function after 1 episode\n",
    "pd.Series(value_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b) TD($\\lambda$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General TD parameters\n",
    "gamma = 1.0\n",
    "learning_rate = 0.1\n",
    "initial_value = 0.0\n",
    "\n",
    "# TD-Lambda parameters\n",
    "lam = 0.5\n",
    "value_function = ValueFunctionDiscreteStates(game.states, \n",
    "                                             game.terminal_states, \n",
    "                                             init_value=0.0)\n",
    "\n",
    "# Environment setup\n",
    "game = RandomWalkGame(size=19, terminal_rewards={'T1': -1.0, 'T2': 1.0})\n",
    "actions = ['r']*10\n",
    "role = 1\n",
    "\n",
    "prev_state = game.generate_state_key(game.start_state, role)\n",
    "prev_reward = None\n",
    "t = 0\n",
    "while not game.game_over:\n",
    "\n",
    "    # Behaviour policy\n",
    "    move = (role, actions[t])\n",
    "    game.make_move(move)\n",
    "\n",
    "    # Get rewards\n",
    "    if not game.game_over:\n",
    "        reward = game.get_rewards()[role]\n",
    "    else:\n",
    "        reward = game.get_terminal_rewards()[role]\n",
    "    \n",
    "    current_state = game.generate_state_key(game.state, role)\n",
    "    current_state_value = value_function(current_state)\n",
    "\n",
    "    print(f\"{prev_state} -> {current_state}, {reward}\")\n",
    "\n",
    "    # Update the value function weights\n",
    "    value_function.update_weights(current_state, prev_state, reward,\n",
    "                                  lam, gamma, learning_rate)\n",
    "\n",
    "    prev_state = current_state\n",
    "    prev_reward = reward\n",
    "\n",
    "    # Update timestep\n",
    "    t += 1\n",
    "\n",
    "# Value function after 1 episode\n",
    "values = {state: value_function(state) for state in game.states}\n",
    "pd.Series(values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (c) TD($\\lambda$) With Simple Linear Approximation of State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General TD parameters\n",
    "gamma = 1.0\n",
    "learning_rate = 0.1\n",
    "initial_value = 0.0\n",
    "\n",
    "# TD-Lambda parameters\n",
    "lam = 0.5\n",
    "value_function = ValueApproxFunction(game)\n",
    "\n",
    "# Environment setup\n",
    "game = RandomWalkGame(size=19, terminal_rewards={'T1': -1.0, 'T2': 1.0})\n",
    "actions = ['r']*10\n",
    "role = 1\n",
    "\n",
    "prev_states = [game.start_state]\n",
    "prev_rewards = [None]\n",
    "t = 0\n",
    "while not game.game_over:\n",
    "\n",
    "    # Behaviour policy\n",
    "    move = (role, actions[t])\n",
    "    game.make_move(move)\n",
    "\n",
    "    # Get rewards\n",
    "    if not game.game_over:\n",
    "        reward = game.get_rewards()[role]\n",
    "    else:\n",
    "        reward = game.get_terminal_rewards()[role]\n",
    "\n",
    "    state_key = game.generate_state_key(game.state, role)\n",
    "    prev_state = prev_states[-1]\n",
    "    prev_states.append(state_key)\n",
    "    prev_rewards.append(reward)\n",
    "\n",
    "    if not game.game_over:\n",
    "        # Update the value for state in timestep tau\n",
    "        td_lambda_update(value_function, prev_state, state_key, \n",
    "                         reward, t, lam, gamma)\n",
    "\n",
    "    # Update timestep\n",
    "    t += 1\n",
    "\n",
    "assert game.game_over\n",
    "\n",
    "# Complete state-value update for final timestep (to terminal state)\n",
    "td_lambda_update(value_function, prev_state, state_key, reward, t, lam, gamma)\n",
    "\n",
    "# Value function after 1 episode\n",
    "values = {state: value_function.value(state) for state in game.states}\n",
    "pd.Series(values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test 2 - 10 Episodes Alternating Right, Left, Right, ... etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a) N-Step TD Updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_runs = 10\n",
    "\n",
    "# General TD parameters\n",
    "gamma = 1.0\n",
    "learning_rate = 0.1\n",
    "initial_value = 0.0\n",
    "\n",
    "# N-step TD parameters\n",
    "n = 10\n",
    "value_function = {state_key: initial_value for state_key in game.states}\n",
    "\n",
    "# Environment setup\n",
    "game = RandomWalkGame(size=19, terminal_rewards={'T1': -1.0, 'T2': 1.0})\n",
    "actions = ['r', 'l', 'r', 'l', 'r', 'l', 'r', 'l', 'r', 'l']\n",
    "role = 1\n",
    "\n",
    "saved_values = []\n",
    "for episode in range(0, n_runs):\n",
    "    game.reset()\n",
    "    action = actions[episode]  # Different action each episode\n",
    "\n",
    "    prev_states = [game.start_state]\n",
    "    prev_rewards = [None]\n",
    "    t = 0\n",
    "    while not game.game_over:\n",
    "\n",
    "        # Behaviour policy\n",
    "        move = (role, action)\n",
    "        game.make_move(move)\n",
    "\n",
    "        # Get rewards\n",
    "        if not game.game_over:\n",
    "            reward = game.get_rewards()[role]\n",
    "        else:\n",
    "            reward = game.get_terminal_rewards()[role]\n",
    "        if reward != 0:\n",
    "            print(f\"{prev_state} -> {current_state}, {reward}\")\n",
    "\n",
    "        state_key = game.generate_state_key(game.state, role)\n",
    "        prev_states.append(state_key)\n",
    "        prev_rewards.append(reward)\n",
    "\n",
    "        if not game.game_over:\n",
    "            # Update the value for state in timestep tau\n",
    "            tau = t - n + 1\n",
    "            td_n_step_update(value_function, prev_states, prev_rewards, \n",
    "                             tau, gamma, learning_rate)\n",
    "\n",
    "        # Update timestep\n",
    "        t += 1\n",
    "\n",
    "    assert game.game_over\n",
    "\n",
    "    # Complete final state-value updates for timesteps tau\n",
    "    # to current (terminal) timestep\n",
    "    for tau in range(t - n, t):\n",
    "        td_n_step_update(value_function, prev_states, prev_rewards, \n",
    "                         tau, gamma, learning_rate, t_max=t)\n",
    "    \n",
    "    saved_values.append(pd.Series(value_function, name=episode))\n",
    "\n",
    "# Final value estimates\n",
    "print(pd.Series(value_function))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_value_estimates(saved_values):\n",
    "    terminal_states = game.terminal_states\n",
    "    combined_results = pd.concat(saved_values, axis=1).drop(terminal_states)\n",
    "    combined_results.plot(style='o-', figsize=(8,4))\n",
    "    plt.grid()\n",
    "    plt.xlabel('State')\n",
    "    plt.ylabel('Value Estimate')\n",
    "    plt.title('State Value Estimates after Each Episode')\n",
    "    plt.legend(title='Episode', bbox_to_anchor=(1.04,1), \n",
    "               loc=\"upper left\")\n",
    "    plt.show()\n",
    "\n",
    "plot_value_estimates(saved_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b) TD(λ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_runs = 10\n",
    "\n",
    "# General TD parameters\n",
    "gamma = 1.0\n",
    "learning_rate = 0.1\n",
    "initial_value = 0.0\n",
    "\n",
    "# TD-Lambda parameters\n",
    "lam = 1.0\n",
    "value_function = ValueFunctionDiscreteStates(game.states, \n",
    "                                             game.terminal_states, \n",
    "                                             init_value=0.0)\n",
    "\n",
    "# Environment setup\n",
    "game = RandomWalkGame(size=19, terminal_rewards={'T1': -1.0, 'T2': 1.0})\n",
    "actions = ['r', 'l', 'r', 'l', 'r', 'l', 'r', 'l', 'r', 'l']\n",
    "role = 1\n",
    "\n",
    "saved_values = []\n",
    "for episode in range(0, n_runs):\n",
    "    game.reset()\n",
    "    action = actions[episode]  # Different action each episode\n",
    "\n",
    "    prev_state = game.generate_state_key(game.start_state, role)\n",
    "    prev_reward = None\n",
    "    t = 0\n",
    "    while not game.game_over:\n",
    "\n",
    "        # Behaviour policy\n",
    "        move = (role, action)\n",
    "        game.make_move(move)\n",
    "\n",
    "        # Get rewards\n",
    "        if not game.game_over:\n",
    "            reward = game.get_rewards()[role]\n",
    "        else:\n",
    "            reward = game.get_terminal_rewards()[role]\n",
    "\n",
    "        current_state = game.generate_state_key(game.state, role)\n",
    "        current_state_value = value_function(current_state)\n",
    "        if reward != 0:\n",
    "            print(f\"{prev_state} -> {current_state}, {reward}\")\n",
    "\n",
    "        # Update the value function weights\n",
    "        value_function.update_weights(current_state, prev_state, reward,\n",
    "                                      lam, gamma, learning_rate)\n",
    "\n",
    "        prev_state = current_state\n",
    "        prev_reward = reward\n",
    "\n",
    "        # Update timestep\n",
    "        t += 1\n",
    "    \n",
    "    values = {state: value_function(state) for state in game.states}\n",
    "    saved_values.append(pd.Series(values, name=episode))\n",
    "\n",
    "# Final value estimates\n",
    "pd.Series(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_value_estimates(saved_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (c) TD($\\lambda$) With Linear Input Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_runs = 10\n",
    "\n",
    "# General TD parameters\n",
    "gamma = 1.0\n",
    "learning_rate = 0.1\n",
    "initial_value = 0.0\n",
    "\n",
    "# TD-Lambda parameters\n",
    "value_function = ValueApproxFunction(game)\n",
    "lam = 0.5\n",
    "\n",
    "# Environment setup\n",
    "game = RandomWalkGame(size=19, terminal_rewards={'T1': -1.0, 'T2': 1.0})\n",
    "#actions = ['r']*10\n",
    "actions = ['r', 'l', 'r', 'l', 'r', 'l', 'r', 'l', 'r', 'l']\n",
    "role = 1\n",
    "\n",
    "saved_values = []\n",
    "for episode in range(0, n_runs):\n",
    "    game.reset()\n",
    "    action = actions[episode]  # Different action each episode\n",
    "\n",
    "    prev_states = [game.start_state]\n",
    "    prev_rewards = [None]\n",
    "    t = 0\n",
    "    while not game.game_over:\n",
    "\n",
    "        # Behaviour policy\n",
    "        move = (role, action)\n",
    "        game.make_move(move)\n",
    "\n",
    "        # Get rewards\n",
    "        if not game.game_over:\n",
    "            reward = game.get_rewards()[role]\n",
    "        else:\n",
    "            reward = game.get_terminal_rewards()[role]\n",
    "\n",
    "        state_key = game.generate_state_key(game.state, role)\n",
    "        prev_state = prev_states[-1]\n",
    "        prev_states.append(state_key)\n",
    "        prev_rewards.append(reward)\n",
    "\n",
    "        if not game.game_over:\n",
    "            # Update the value for state in timestep tau\n",
    "            td_lambda_update(value_function, prev_state, state_key, \n",
    "                             reward, t, lam, gamma)\n",
    "\n",
    "        # Update timestep\n",
    "        t += 1\n",
    "\n",
    "    assert game.game_over\n",
    "\n",
    "    # Complete state-value update for final timestep (to terminal state)\n",
    "    td_lambda_update(value_function, prev_state, state_key, \n",
    "                     reward, t, lam, gamma)\n",
    "\n",
    "    values = {state: value_function.value(state) for state in game.states}\n",
    "    saved_values.append(pd.Series(values, name=episode))\n",
    "\n",
    "# Final value estimates\n",
    "print(pd.Series(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_value_estimates(saved_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test 3 - 10 Episodes with Random Walk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a) N-Step TD Updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_runs = 10\n",
    "\n",
    "# General TD parameters\n",
    "gamma = 1.0\n",
    "learning_rate = 0.1\n",
    "initial_value = 0.0\n",
    "\n",
    "# N-step TD parameters\n",
    "n = 10\n",
    "value_function = {state_key: initial_value for state_key in game.states}\n",
    "\n",
    "# Environment setup\n",
    "game = RandomWalkGame(size=19, terminal_rewards={'T1': -1.0, 'T2': 1.0})\n",
    "actions = ['r', 'l']\n",
    "role = 1\n",
    "\n",
    "saved_values = []\n",
    "for episode in range(0, n_runs):\n",
    "    game.reset()\n",
    "\n",
    "    prev_states = [game.start_state]\n",
    "    prev_rewards = [None]\n",
    "    t = 0\n",
    "    while not game.game_over:\n",
    "\n",
    "        # Behaviour policy\n",
    "        action = random.choice(actions)\n",
    "        move = (role, action)\n",
    "        game.make_move(move)\n",
    "\n",
    "        # Get rewards\n",
    "        if not game.game_over:\n",
    "            reward = game.get_rewards()[role]\n",
    "        else:\n",
    "            reward = game.get_terminal_rewards()[role]\n",
    "\n",
    "        state_key = game.generate_state_key(game.state, role)\n",
    "        prev_states.append(state_key)\n",
    "        prev_rewards.append(reward)\n",
    "\n",
    "        if not game.game_over:\n",
    "            # Update the value for state in timestep tau\n",
    "            tau = t - n + 1\n",
    "            td_n_step_update(value_function, prev_states, prev_rewards, \n",
    "                             tau, gamma)\n",
    "\n",
    "        # Update timestep\n",
    "        t += 1\n",
    "\n",
    "    assert game.game_over\n",
    "\n",
    "    # Complete final state-value updates for timesteps tau\n",
    "    # to current (terminal) timestep\n",
    "    for tau in range(t - n, t):\n",
    "        td_n_step_update(value_function, prev_states, prev_rewards, \n",
    "                         tau, gamma, t_max=t)\n",
    "    \n",
    "    saved_values.append(pd.Series(value_function, name=episode))\n",
    "\n",
    "# Final value estimates\n",
    "print(pd.Series(value_function))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_value_estimates(saved_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b) TD($\\lambda$) With Linear Input Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_runs = 10\n",
    "\n",
    "# General TD parameters\n",
    "gamma = 1.0\n",
    "learning_rate = 0.1\n",
    "initial_value = 0.0\n",
    "\n",
    "# TD-Lambda parameters\n",
    "value_function = ValueApproxFunction(game)\n",
    "lam = 0.5\n",
    "\n",
    "# Environment setup\n",
    "game = RandomWalkGame(size=19, terminal_rewards={'T1': -1.0, 'T2': 1.0})\n",
    "actions = ['r', 'l']\n",
    "role = 1\n",
    "\n",
    "saved_values = []\n",
    "for episode in range(0, n_runs):\n",
    "    game.reset()\n",
    "\n",
    "    prev_states = [game.start_state]\n",
    "    prev_rewards = [None]\n",
    "    t = 0\n",
    "    while not game.game_over:\n",
    "\n",
    "        # Behaviour policy\n",
    "        action = random.choice(actions)\n",
    "        move = (role, action)\n",
    "        game.make_move(move)\n",
    "\n",
    "        # Get rewards\n",
    "        if not game.game_over:\n",
    "            reward = game.get_rewards()[role]\n",
    "        else:\n",
    "            reward = game.get_terminal_rewards()[role]\n",
    "\n",
    "        state_key = game.generate_state_key(game.state, role)\n",
    "        prev_state = prev_states[-1]\n",
    "        prev_states.append(state_key)\n",
    "        prev_rewards.append(reward)\n",
    "\n",
    "        if not game.game_over:\n",
    "            # Update the value for state in timestep tau\n",
    "            td_lambda_update(value_function, prev_state, state_key, \n",
    "                             reward, t, lam, gamma)\n",
    "\n",
    "        # Update timestep\n",
    "        t += 1\n",
    "\n",
    "    assert game.game_over\n",
    "\n",
    "    # Complete state-value update for final timestep (to terminal state)\n",
    "    td_lambda_update(value_function, prev_state, state_key, \n",
    "                     reward, t, lam, gamma)\n",
    "\n",
    "    values = {state: value_function.value(state) for state in game.states}\n",
    "    saved_values.append(pd.Series(values, name=episode))\n",
    "\n",
    "# Final value estimates\n",
    "print(pd.Series(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_value_estimates(saved_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch]",
   "language": "python",
   "name": "conda-env-torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
