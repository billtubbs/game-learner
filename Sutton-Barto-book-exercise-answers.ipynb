{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sutton & Barto Book\n",
    "\n",
    "## Chapter 4: Dynamic Programming\n",
    "\n",
    "## Demonstration of iterative policy evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<IMG SRC=\"images/gridworld.png\">\n",
    "\n",
    "\n",
    "### Exercise 4.1\n",
    "\n",
    "In Example 4.1, if $\\pi$ is the equiprobable random policy,\n",
    "\n",
    "- What is $q_\\pi(11,down)$?\n",
    "- What is $q_\\pi(7,down)$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0), (0, 1), (0, 2), (0, 3), (1, 0), (1, 1), (1, 2), (1, 3), (2, 0), (2, 1), (2, 2), (2, 3), (3, 0), (3, 1), (3, 2), (3, 3)]\n"
     ]
    }
   ],
   "source": [
    "grid_shape = (4, 4)\n",
    "terminal_state = [(0,0), (3, 3)]\n",
    "\n",
    "states = []\n",
    "for row in range(grid_shape[0]):\n",
    "    for col in range(grid_shape[1]):\n",
    "        p = (row, col)\n",
    "        if not p in terminal_state[1]:\n",
    "            states.append(p)\n",
    "print(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 0): 0,\n",
       " (0, 1): 0,\n",
       " (0, 2): 0,\n",
       " (0, 3): 0,\n",
       " (1, 0): 0,\n",
       " (1, 1): 0,\n",
       " (1, 2): 0,\n",
       " (1, 3): 0,\n",
       " (2, 0): 0,\n",
       " (2, 1): 0,\n",
       " (2, 2): 0,\n",
       " (2, 3): 0,\n",
       " (3, 0): 0,\n",
       " (3, 1): 0,\n",
       " (3, 2): 0,\n",
       " (3, 3): 0}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# State value-function\n",
    "values = {s: 0 for s in states}\n",
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'l': (0, -1), 'u': (-1, 0), 'r': (0, 1), 'd': (1, 0)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions = {\n",
    "            'l': (0, -1),\n",
    "            'u': (-1, 0),\n",
    "            'r': (0, 1),\n",
    "            'd': (1, 0)\n",
    "        }\n",
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "def show_values(values, r=1):\n",
    "    \"\"\"Displays the values rounded to r decimal places.\n",
    "    \"\"\"\n",
    "    \n",
    "    v_array = np.zeros(grid_shape)\n",
    "    for s, v in values.items():\n",
    "        v_array[s] = v\n",
    "    print(v_array.round(r))\n",
    "\n",
    "show_values(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(((0, 0), 'l'), 0.0), (((0, 0), 'u'), 0.0), (((0, 0), 'r'), 0.0)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q (state, action) value function\n",
    "q_values = {}\n",
    "for s in states:\n",
    "    for a in actions:\n",
    "        q_values[(s, a)] = 0.0\n",
    "list(q_values.items())[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0, 2), -1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def move(s, a):\n",
    "    \"\"\"Returns next state and reward given current\n",
    "    state (s) and action (a).\"\"\"\n",
    "\n",
    "    if s in terminal_state:\n",
    "        r = 0\n",
    "    else:\n",
    "        s2 = tuple(np.array(s) + np.array(actions[a]))\n",
    "\n",
    "        # Check if out of bounds\n",
    "        if (s2[0] < 0) or (s2[0] >= grid_shape[0]) or \\\n",
    "            (s2[1] < 0) or (s2[1] >= grid_shape[1]):\n",
    "            s2 = s\n",
    "        else:\n",
    "            s = s2\n",
    "        r = -1\n",
    "\n",
    "    if s in terminal_state:\n",
    "        s = terminal_state[0]\n",
    "\n",
    "    return s, r\n",
    "\n",
    "move((0, 1), 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(((0, 0), 'l'), ((0, 0), 0)),\n",
       " (((0, 0), 'u'), ((0, 0), 0)),\n",
       " (((0, 0), 'r'), ((0, 0), 0)),\n",
       " (((0, 0), 'd'), ((0, 0), 0)),\n",
       " (((0, 1), 'l'), ((0, 0), -1)),\n",
       " (((0, 1), 'u'), ((0, 1), -1)),\n",
       " (((0, 1), 'r'), ((0, 2), -1)),\n",
       " (((0, 1), 'd'), ((1, 1), -1)),\n",
       " (((0, 2), 'l'), ((0, 1), -1)),\n",
       " (((0, 2), 'u'), ((0, 2), -1)),\n",
       " (((0, 2), 'r'), ((0, 3), -1)),\n",
       " (((0, 2), 'd'), ((1, 2), -1)),\n",
       " (((0, 3), 'l'), ((0, 2), -1)),\n",
       " (((0, 3), 'u'), ((0, 3), -1)),\n",
       " (((0, 3), 'r'), ((0, 3), -1)),\n",
       " (((0, 3), 'd'), ((1, 3), -1)),\n",
       " (((1, 0), 'l'), ((1, 0), -1)),\n",
       " (((1, 0), 'u'), ((0, 0), -1)),\n",
       " (((1, 0), 'r'), ((1, 1), -1)),\n",
       " (((1, 0), 'd'), ((2, 0), -1)),\n",
       " (((1, 1), 'l'), ((1, 0), -1)),\n",
       " (((1, 1), 'u'), ((0, 1), -1)),\n",
       " (((1, 1), 'r'), ((1, 2), -1)),\n",
       " (((1, 1), 'd'), ((2, 1), -1)),\n",
       " (((1, 2), 'l'), ((1, 1), -1)),\n",
       " (((1, 2), 'u'), ((0, 2), -1)),\n",
       " (((1, 2), 'r'), ((1, 3), -1)),\n",
       " (((1, 2), 'd'), ((2, 2), -1)),\n",
       " (((1, 3), 'l'), ((1, 2), -1)),\n",
       " (((1, 3), 'u'), ((0, 3), -1)),\n",
       " (((1, 3), 'r'), ((1, 3), -1)),\n",
       " (((1, 3), 'd'), ((2, 3), -1)),\n",
       " (((2, 0), 'l'), ((2, 0), -1)),\n",
       " (((2, 0), 'u'), ((1, 0), -1)),\n",
       " (((2, 0), 'r'), ((2, 1), -1)),\n",
       " (((2, 0), 'd'), ((3, 0), -1)),\n",
       " (((2, 1), 'l'), ((2, 0), -1)),\n",
       " (((2, 1), 'u'), ((1, 1), -1)),\n",
       " (((2, 1), 'r'), ((2, 2), -1)),\n",
       " (((2, 1), 'd'), ((3, 1), -1)),\n",
       " (((2, 2), 'l'), ((2, 1), -1)),\n",
       " (((2, 2), 'u'), ((1, 2), -1)),\n",
       " (((2, 2), 'r'), ((2, 3), -1)),\n",
       " (((2, 2), 'd'), ((3, 2), -1)),\n",
       " (((2, 3), 'l'), ((2, 2), -1)),\n",
       " (((2, 3), 'u'), ((1, 3), -1)),\n",
       " (((2, 3), 'r'), ((2, 3), -1)),\n",
       " (((2, 3), 'd'), ((0, 0), -1)),\n",
       " (((3, 0), 'l'), ((3, 0), -1)),\n",
       " (((3, 0), 'u'), ((2, 0), -1)),\n",
       " (((3, 0), 'r'), ((3, 1), -1)),\n",
       " (((3, 0), 'd'), ((3, 0), -1)),\n",
       " (((3, 1), 'l'), ((3, 0), -1)),\n",
       " (((3, 1), 'u'), ((2, 1), -1)),\n",
       " (((3, 1), 'r'), ((3, 2), -1)),\n",
       " (((3, 1), 'd'), ((3, 1), -1)),\n",
       " (((3, 2), 'l'), ((3, 1), -1)),\n",
       " (((3, 2), 'u'), ((2, 2), -1)),\n",
       " (((3, 2), 'r'), ((0, 0), -1)),\n",
       " (((3, 2), 'd'), ((3, 2), -1)),\n",
       " (((3, 3), 'l'), ((0, 0), 0)),\n",
       " (((3, 3), 'u'), ((0, 0), 0)),\n",
       " (((3, 3), 'r'), ((0, 0), 0)),\n",
       " (((3, 3), 'd'), ((0, 0), 0))]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store all possible game transitions\n",
    "\n",
    "transitions = {}\n",
    "for s in states:\n",
    "    for a in actions:\n",
    "        transitions[(s, a)] = move(s, a)\n",
    "\n",
    "list(transitions.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_policy_with_values(state, action, values, transitions):\n",
    "    \n",
    "    # Requires the state-transition matrix\n",
    "    action_values = [values[transitions[(state, a)][0]] for a in actions]\n",
    "    v_max = max(action_values)\n",
    "    a_greedy = list(actions.keys())[action_values.index(v_max)]\n",
    "\n",
    "    return 1 if action == a_greedy else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_policy_with_q_values(state, action, q_values, transitions=None):\n",
    "\n",
    "    action_values = [values[q_values[(state, a)]] for a in actions]\n",
    "    v_max = max(action_values)\n",
    "    a_greedy = list(actions.keys())[action_values.index(v_max)]\n",
    "\n",
    "    return 1 if action == a_greedy else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_policy(state, action, values=None, transitions=None):\n",
    "\n",
    "    return 1.0/len(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_action(policy, state, values, transitions=None):\n",
    "    \n",
    "    probs = [policy(state, a, values, transitions) for a in actions]\n",
    "    \n",
    "    return np.random.choice(list(actions.keys()), p=probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bellman_equation(policy, states, actions, transitions,  \n",
    "                     values, lr):\n",
    "    \"\"\"Updates the value function using the Bellman\n",
    "    equation (4.5).\"\"\"\n",
    "    \n",
    "    v = values.copy()\n",
    "    for s in states:\n",
    "        \n",
    "        sum_values = 0\n",
    "        for a in actions:\n",
    "            \n",
    "            s2, r = transitions[(s, a)]\n",
    "            v2 = values[s2]\n",
    "            p = policy(s, a, values)\n",
    "            sum_values += p*(r + lr*v2)\n",
    "\n",
    "        v[s] = sum_values\n",
    "    \n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_policy(policy, states, actions, transitions,  \n",
    "                    values, lr=1.0, theta=0.01, max_iter=1000,\n",
    "                    show=True):\n",
    "\n",
    "    iteration = 0\n",
    "    if show:\n",
    "            print(\"\\nk =\", iteration)\n",
    "            show_values(values)\n",
    "\n",
    "    while iteration < max_iter:\n",
    "\n",
    "        updated_values = bellman_equation(policy, states, actions, \n",
    "                                          transitions, values, lr=lr)\n",
    "\n",
    "        delta = np.abs(\n",
    "            np.array(list(updated_values.values())) -\n",
    "            np.array(list(values.values()))\n",
    "        ).max()\n",
    "        \n",
    "        values = updated_values\n",
    "        iteration += 1\n",
    "        \n",
    "        if show:\n",
    "            print(\"\\nk =\", iteration)\n",
    "            show_values(values)\n",
    "\n",
    "        if delta < theta:\n",
    "            break\n",
    "    \n",
    "    if iteration == max_iter:\n",
    "        print(\"\\nMaximum iterations reached.\")\n",
    "    else:\n",
    "        print(\"\\nConverged to delta < %f after %d iterations\" % \n",
    "              (theta, iteration))\n",
    "    \n",
    "    return values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Equi-probable random policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = {s: 0 for s in states}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "k = 0\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "\n",
      "k = 1\n",
      "[[ 0. -1. -1. -1.]\n",
      " [-1. -1. -1. -1.]\n",
      " [-1. -1. -1. -1.]\n",
      " [-1. -1. -1.  0.]]\n",
      "\n",
      "k = 2\n",
      "[[ 0.  -1.8 -2.  -2. ]\n",
      " [-1.8 -2.  -2.  -2. ]\n",
      " [-2.  -2.  -2.  -1.8]\n",
      " [-2.  -2.  -1.8  0. ]]\n",
      "\n",
      "k = 3\n",
      "[[ 0.  -2.4 -2.9 -3. ]\n",
      " [-2.4 -2.9 -3.  -2.9]\n",
      " [-2.9 -3.  -2.9 -2.4]\n",
      " [-3.  -2.9 -2.4  0. ]]\n",
      "\n",
      "k = 4\n",
      "[[ 0.  -3.1 -3.8 -4. ]\n",
      " [-3.1 -3.7 -3.9 -3.8]\n",
      " [-3.8 -3.9 -3.7 -3.1]\n",
      " [-4.  -3.8 -3.1  0. ]]\n",
      "\n",
      "k = 5\n",
      "[[ 0.  -3.7 -4.7 -4.9]\n",
      " [-3.7 -4.5 -4.8 -4.7]\n",
      " [-4.7 -4.8 -4.5 -3.7]\n",
      " [-4.9 -4.7 -3.7  0. ]]\n",
      "\n",
      "k = 6\n",
      "[[ 0.  -4.2 -5.5 -5.8]\n",
      " [-4.2 -5.2 -5.6 -5.5]\n",
      " [-5.5 -5.6 -5.2 -4.2]\n",
      " [-5.8 -5.5 -4.2  0. ]]\n",
      "\n",
      "k = 7\n",
      "[[ 0.  -4.7 -6.3 -6.7]\n",
      " [-4.7 -5.9 -6.4 -6.3]\n",
      " [-6.3 -6.4 -5.9 -4.7]\n",
      " [-6.7 -6.3 -4.7  0. ]]\n",
      "\n",
      "k = 8\n",
      "[[ 0.  -5.2 -7.  -7.5]\n",
      " [-5.2 -6.5 -7.1 -7. ]\n",
      " [-7.  -7.1 -6.5 -5.2]\n",
      " [-7.5 -7.  -5.2  0. ]]\n",
      "\n",
      "k = 9\n",
      "[[ 0.  -5.7 -7.7 -8.2]\n",
      " [-5.7 -7.2 -7.8 -7.7]\n",
      " [-7.7 -7.8 -7.2 -5.7]\n",
      " [-8.2 -7.7 -5.7  0. ]]\n",
      "\n",
      "k = 10\n",
      "[[ 0.  -6.1 -8.4 -9. ]\n",
      " [-6.1 -7.7 -8.4 -8.4]\n",
      " [-8.4 -8.4 -7.7 -6.1]\n",
      " [-9.  -8.4 -6.1  0. ]]\n",
      "\n",
      "Maximum iterations reached.\n"
     ]
    }
   ],
   "source": [
    "values = evaluate_policy(random_policy, states, actions, transitions, \n",
    "                         values, max_iter=10, show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Greedy policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 0): 0.0,\n",
       " (0, 1): -6.137969970703125,\n",
       " (0, 2): -8.35235595703125,\n",
       " (0, 3): -8.967315673828125,\n",
       " (1, 0): -6.137969970703125,\n",
       " (1, 1): -7.737396240234375,\n",
       " (1, 2): -8.427825927734375,\n",
       " (1, 3): -8.35235595703125,\n",
       " (2, 0): -8.35235595703125,\n",
       " (2, 1): -8.427825927734375,\n",
       " (2, 2): -7.737396240234375,\n",
       " (2, 3): -6.137969970703125,\n",
       " (3, 0): -8.967315673828125,\n",
       " (3, 1): -8.35235595703125,\n",
       " (3, 2): -6.137969970703125,\n",
       " (3, 3): 0.0}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'r'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_action(greedy_policy_with_values, (2,2), values, transitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['l' 'l' 'l' 'l']\n",
      " ['u' 'l' 'l' 'd']\n",
      " ['u' 'u' 'r' 'd']\n",
      " ['u' 'r' 'r' 'l']]\n"
     ]
    }
   ],
   "source": [
    "def show_actions(states, policy, values, transitions=None):\n",
    "    \n",
    "    a_array = np.array(['_']*np.prod(grid_shape), dtype='<U1').reshape(grid_shape)\n",
    "    for s in states:\n",
    "        a_array[s] = policy_action(policy, s, values, transitions)\n",
    "    \n",
    "    print(a_array)\n",
    "\n",
    "# Optimal actions\n",
    "show_actions(states, greedy_policy_with_values, values, transitions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Calculate Q-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_values_from_values(states, actions, values, transitions, \n",
    "                         lr=1.0):\n",
    "\n",
    "    q_values = {}\n",
    "    \n",
    "    for s in states:\n",
    "        \n",
    "        sum_values = 0\n",
    "        for a in actions:\n",
    "            next_state = transitions[(s, a)]\n",
    "            # Q-value is value of next state + reward (?)\n",
    "            v_next = values[next_state[0]] + next_state[1]\n",
    "            q_values[(s, a)] = v_next\n",
    "    \n",
    "    return q_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{((0, 0), 'l'): 0.0,\n",
       " ((0, 0), 'u'): 0.0,\n",
       " ((0, 0), 'r'): 0.0,\n",
       " ((0, 0), 'd'): 0.0,\n",
       " ((0, 1), 'l'): -1.0,\n",
       " ((0, 1), 'u'): -7.137969970703125,\n",
       " ((0, 1), 'r'): -9.35235595703125,\n",
       " ((0, 1), 'd'): -8.737396240234375,\n",
       " ((0, 2), 'l'): -7.137969970703125,\n",
       " ((0, 2), 'u'): -9.35235595703125,\n",
       " ((0, 2), 'r'): -9.967315673828125,\n",
       " ((0, 2), 'd'): -9.427825927734375,\n",
       " ((0, 3), 'l'): -9.35235595703125,\n",
       " ((0, 3), 'u'): -9.967315673828125,\n",
       " ((0, 3), 'r'): -9.967315673828125,\n",
       " ((0, 3), 'd'): -9.35235595703125,\n",
       " ((1, 0), 'l'): -7.137969970703125,\n",
       " ((1, 0), 'u'): -1.0,\n",
       " ((1, 0), 'r'): -8.737396240234375,\n",
       " ((1, 0), 'd'): -9.35235595703125,\n",
       " ((1, 1), 'l'): -7.137969970703125,\n",
       " ((1, 1), 'u'): -7.137969970703125,\n",
       " ((1, 1), 'r'): -9.427825927734375,\n",
       " ((1, 1), 'd'): -9.427825927734375,\n",
       " ((1, 2), 'l'): -8.737396240234375,\n",
       " ((1, 2), 'u'): -9.35235595703125,\n",
       " ((1, 2), 'r'): -9.35235595703125,\n",
       " ((1, 2), 'd'): -8.737396240234375,\n",
       " ((1, 3), 'l'): -9.427825927734375,\n",
       " ((1, 3), 'u'): -9.967315673828125,\n",
       " ((1, 3), 'r'): -9.35235595703125,\n",
       " ((1, 3), 'd'): -7.137969970703125,\n",
       " ((2, 0), 'l'): -9.35235595703125,\n",
       " ((2, 0), 'u'): -7.137969970703125,\n",
       " ((2, 0), 'r'): -9.427825927734375,\n",
       " ((2, 0), 'd'): -9.967315673828125,\n",
       " ((2, 1), 'l'): -9.35235595703125,\n",
       " ((2, 1), 'u'): -8.737396240234375,\n",
       " ((2, 1), 'r'): -8.737396240234375,\n",
       " ((2, 1), 'd'): -9.35235595703125,\n",
       " ((2, 2), 'l'): -9.427825927734375,\n",
       " ((2, 2), 'u'): -9.427825927734375,\n",
       " ((2, 2), 'r'): -7.137969970703125,\n",
       " ((2, 2), 'd'): -7.137969970703125,\n",
       " ((2, 3), 'l'): -8.737396240234375,\n",
       " ((2, 3), 'u'): -9.35235595703125,\n",
       " ((2, 3), 'r'): -7.137969970703125,\n",
       " ((2, 3), 'd'): -1.0,\n",
       " ((3, 0), 'l'): -9.967315673828125,\n",
       " ((3, 0), 'u'): -9.35235595703125,\n",
       " ((3, 0), 'r'): -9.35235595703125,\n",
       " ((3, 0), 'd'): -9.967315673828125,\n",
       " ((3, 1), 'l'): -9.967315673828125,\n",
       " ((3, 1), 'u'): -9.427825927734375,\n",
       " ((3, 1), 'r'): -7.137969970703125,\n",
       " ((3, 1), 'd'): -9.35235595703125,\n",
       " ((3, 2), 'l'): -9.35235595703125,\n",
       " ((3, 2), 'u'): -8.737396240234375,\n",
       " ((3, 2), 'r'): -1.0,\n",
       " ((3, 2), 'd'): -7.137969970703125,\n",
       " ((3, 3), 'l'): 0.0,\n",
       " ((3, 3), 'u'): 0.0,\n",
       " ((3, 3), 'r'): 0.0,\n",
       " ((3, 3), 'd'): 0.0}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_values = q_values_from_values(states, actions, values, transitions)\n",
    "q_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$q_\\pi(11,down)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_values[((2, 3), 'd')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$q_\\pi(7,down)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-7.137969970703125"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_values[((1, 3), 'd')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is this correct?  Or should it be the same as v_next (-6.13797)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-6.137969970703125"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values[(2, 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
